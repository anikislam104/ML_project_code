{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training data\n",
    "train_labels = pd.read_excel('../mini_dataset/Training_Set/train_labels.xlsx')\n",
    "# Read test data\n",
    "test_labels = pd.read_csv('../mini_dataset/Test_Set/test_labels.csv')\n",
    "# Read validation data\n",
    "validation_labels = pd.read_csv('../mini_dataset/Validation_Set/validation_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Disease_Risk</th>\n",
       "      <th>DR</th>\n",
       "      <th>ARMD</th>\n",
       "      <th>MH</th>\n",
       "      <th>DN</th>\n",
       "      <th>MYA</th>\n",
       "      <th>BRVO</th>\n",
       "      <th>TSLN</th>\n",
       "      <th>ERM</th>\n",
       "      <th>...</th>\n",
       "      <th>CME</th>\n",
       "      <th>PTCR</th>\n",
       "      <th>CF</th>\n",
       "      <th>VH</th>\n",
       "      <th>MCA</th>\n",
       "      <th>VS</th>\n",
       "      <th>BRAO</th>\n",
       "      <th>PLQ</th>\n",
       "      <th>HPED</th>\n",
       "      <th>CL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Disease_Risk  DR  ARMD  MH  DN  MYA  BRVO  TSLN  ERM  ...  CME  PTCR  \\\n",
       "0   1             1   1     0   0   0    0     0     0    0  ...    0     0   \n",
       "1   2             1   1     0   0   0    0     0     0    0  ...    0     0   \n",
       "2   3             1   1     0   0   0    0     0     0    0  ...    0     0   \n",
       "3   4             1   0     0   1   0    0     0     0    0  ...    0     0   \n",
       "4   5             1   1     0   0   0    0     0     0    0  ...    0     0   \n",
       "\n",
       "   CF  VH  MCA  VS  BRAO  PLQ  HPED  CL  \n",
       "0   0   0    0   0     0    0     0   0  \n",
       "1   0   0    0   0     0    0     0   0  \n",
       "2   0   0    0   0     0    0     0   0  \n",
       "3   0   0    0   0     0    0     0   0  \n",
       "4   0   0    0   0     0    0     0   0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18060/352456990.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrain_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../mini_dataset/Training_Set/train_images/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#convert to grayscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m           \u001b[1;31m#resize to 224x224\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#read 300 training images\n",
    "train_images = []\n",
    "for i in range(300):\n",
    "    img = cv2.imread('../mini_dataset/Training_Set/train_images/' + str(i+1) + '.png')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #convert to grayscale\n",
    "    img = cv2.resize(img, (28, 28))           #resize to 224x224\n",
    "    train_images.append(img)                    #append to list\n",
    "\n",
    "#array of training images\n",
    "train_images = np.array(train_images)           #convert to array\n",
    "print(train_images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize training images\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "#X = (X - mu) / sigma\n",
    "train_images = (train_images - np.mean(train_images)) / np.std(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape training images to 2D\n",
    "train_images = train_images.reshape(train_images.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape training images to 3D\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "#covert to grayscale\n",
    "train_images = np.repeat(train_images, 3, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RBM architecture\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "\n",
    "#RBM model\n",
    "rbm = BernoulliRBM(n_components=100, learning_rate=0.01, batch_size=10, n_iter=20, verbose=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -525.10, time = 0.07s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -634.92, time = 0.07s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -743.57, time = 0.06s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -868.81, time = 0.07s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -976.84, time = 0.08s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -1095.65, time = 0.08s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -1200.67, time = 0.08s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -1307.45, time = 0.09s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -1423.16, time = 0.08s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -1534.89, time = 0.08s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -1653.94, time = 0.08s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -1761.90, time = 0.08s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -1882.76, time = 0.08s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -1996.69, time = 0.08s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -2110.56, time = 0.10s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -2229.97, time = 0.10s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -2331.19, time = 0.11s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -2455.41, time = 0.09s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -2571.57, time = 0.09s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -2682.15, time = 0.09s\n"
     ]
    }
   ],
   "source": [
    "#train RBM\n",
    "rbm_features_train = rbm.fit_transform(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 28, 28)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images.shape: (300, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_images.shape: {}\".format(train_images.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set the number of visible and hidden units in the RBM\n",
    "num_visible = 28 * 28   # number of pixels in the images\n",
    "num_hidden = 100\n",
    "\n",
    "# Initialize the weight matrix with small random values\n",
    "rbm_weights = np.random.randn(num_visible, num_hidden) * 0.1\n",
    "\n",
    "# Initialize the visible bias vector with small random values\n",
    "rbm_visible_bias = np.zeros((1, num_visible))\n",
    "\n",
    "# Initialize the hidden bias vector with small random values\n",
    "rbm_hidden_bias = np.zeros((1, num_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample only one training example from 300 training examples\n",
    "train_example = train_images[0]\n",
    "\n",
    "# Present the training example to the RBM as the visible l\n",
    "#  rbm_visible shape = (1, 784)\n",
    "rbm_visible = train_example.reshape(1, num_visible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_probabilities = 1.0 / (1.0 + np.exp(-np.dot(rbm_visible, rbm_weights) - rbm_hidden_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbm visible shape:  (1, 784)\n",
      "rbm weights shape:  (784, 100)\n",
      "rbm hidden bias shape:  (1, 100)\n",
      "hidden probabilities shape:  (1, 100)\n",
      "train example shape:  (28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"rbm visible shape: \", rbm_visible.shape)\n",
    "print(\"rbm weights shape: \", rbm_weights.shape)\n",
    "print(\"rbm hidden bias shape: \", rbm_hidden_bias.shape)\n",
    "print(\"hidden probabilities shape: \", hidden_probabilities.shape)\n",
    "print(\"train example shape: \", train_example.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the hidden layer activations from the probabilities\n",
    "hidden_states = hidden_probabilities > np.random.rand(num_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct the visible layer activations from the hidden layer activations\n",
    "reconstructed_visible_probabilities = 1.0 / (1.0 + np.exp(-np.dot(hidden_states, rbm_weights.T) - rbm_visible_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the probabilities of the hidden layer activations given the reconstructed visible layer activations\n",
    "reconstructed_hidden_probabilities = 1.0 / (1.0 + np.exp(-np.dot(reconstructed_visible_probabilities, rbm_weights) - rbm_hidden_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the gradients of the weight matrix and biases\n",
    "pos_grad_weights = np.dot(rbm_visible.T, hidden_probabilities)\n",
    "neg_grad_weights = np.dot(reconstructed_visible_probabilities.T, reconstructed_hidden_probabilities)\n",
    "pos_grad_visible_bias = np.mean(rbm_visible, axis=0)\n",
    "neg_grad_visible_bias = np.mean(reconstructed_visible_probabilities, axis=0)\n",
    "pos_grad_hidden_bias = np.mean(hidden_probabilities, axis=0)\n",
    "neg_grad_hidden_bias = np.mean(reconstructed_hidden_probabilities, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the weight matrix and biases\n",
    "rbm_weights += 0.01 * (pos_grad_weights - neg_grad_weights) / train_example.shape[0] \n",
    "rbm_visible_bias += 0.01 * (pos_grad_visible_bias - neg_grad_visible_bias) / train_example.shape[0]\n",
    "rbm_hidden_bias += 0.01 * (pos_grad_hidden_bias - neg_grad_hidden_bias) / train_example.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def gibbs_sampling(v, W, b_h, b_v, num_iterations):\n",
    "    \"\"\"\n",
    "    Performs Gibbs sampling on a restricted Boltzmann machine (RBM).\n",
    "    \n",
    "    Parameters:\n",
    "    - v: visible layer of the RBM\n",
    "    - W: weight matrix of the RBM\n",
    "    - b_h: bias vector of the hidden layer\n",
    "    - b_v: bias vector of the visible layer\n",
    "    - num_iterations: number of Gibbs sampling iterations to perform\n",
    "    \n",
    "    Returns:\n",
    "    - h: final state of the hidden layer after Gibbs sampling\n",
    "    \"\"\"\n",
    "    \n",
    "    h = np.random.binomial(1, 0.5, size=W.shape[1])  # initialize hidden layer with random binary values\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        v_prob = 1.0 / (1.0 + np.exp(-np.dot(h, W.T) - b_v))  # calculate probabilities of visible layer given hidden layer\n",
    "        v = np.random.binomial(1, v_prob)  # sample visible layer\n",
    "        h_prob = 1.0 / (1.0 + np.exp(-np.dot(v, W) - b_h))  # calculate probabilities of hidden layer given visible layer\n",
    "        h = np.random.binomial(1, h_prob)  # sample hidden layer\n",
    "    \n",
    "    return h\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train using gibbs sampling\n",
    "for i in range(100):\n",
    "    # sample a training example\n",
    "    train_example = train_images[i]\n",
    "    train_example = train_example.reshape(1, num_visible)\n",
    "    \n",
    "    # perform gibbs sampling\n",
    "    h = gibbs_sampling(train_example, rbm_weights, rbm_hidden_bias, rbm_visible_bias, 100)\n",
    "    \n",
    "    # calculate the gradients of the weight matrix and biases\n",
    "    pos_grad_weights = np.dot(train_example.T, h)\n",
    "    neg_grad_weights = np.dot(reconstructed_visible_probabilities.T, reconstructed_hidden_probabilities)\n",
    "    pos_grad_visible_bias = np.mean(train_example, axis=0)\n",
    "    neg_grad_visible_bias = np.mean(reconstructed_visible_probabilities, axis=0)\n",
    "    pos_grad_hidden_bias = np.mean(h, axis=0)\n",
    "    neg_grad_hidden_bias = np.mean(reconstructed_hidden_probabilities, axis=0)\n",
    "    \n",
    "    # update the weight matrix and biases\n",
    "    rbm_weights += 0.01 * (pos_grad_weights - neg_grad_weights) / train_example.shape[0] \n",
    "    rbm_visible_bias += 0.01 * (pos_grad_visible_bias - neg_grad_visible_bias) / train_example.shape[0]\n",
    "    rbm_hidden_bias += 0.01 * (pos_grad_hidden_bias - neg_grad_hidden_bias) / train_example.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#read test data\n",
    "test_images = []\n",
    "for i in range(100):\n",
    "    img = cv2.imread('../mini_dataset/Test_Set/test_images/' + str(i+1) + '.png')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #convert to grayscale\n",
    "    img = cv2.resize(img, (28, 28))           #resize to 224x224\n",
    "    test_images.append(img)                    #append to list\n",
    "\n",
    "#array of training images\n",
    "test_images = np.array(test_images)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 ... 1 1 0]]\n",
      "\n",
      " [[0 0 0 ... 1 1 0]]\n",
      "\n",
      " [[0 0 0 ... 1 1 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 1 1 0]]\n",
      "\n",
      " [[0 0 0 ... 1 1 0]]\n",
      "\n",
      " [[0 0 0 ... 1 1 0]]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72810415e89f4781583f83fd436e59b66cd4ea53cdb796548e396a9e08c48419"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
